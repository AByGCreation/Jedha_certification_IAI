# üîÑ APACHE AIRFLOW - ETL/ELT ORCHESTRATION

## Vue d'ensemble

Apache Airflow orchestre les pipelines ETL/ELT de la plateforme de d√©tection de fraude.

## üåê Acc√®s

**URL:** http://localhost:8080  
**Login:** admin  
**Password:** stripe_password

## üìä DAGs Disponibles

### 1. **etl_postgres_to_clickhouse** 
**Fr√©quence:** Quotidienne (2h du matin)

Pipeline ETL principal : PostgreSQL (OLTP) ‚Üí ClickHouse (OLAP)

**√âtapes:**
1. **Extract** - Extraction transactions PostgreSQL
2. **Transform** - Conversion types, nettoyage
3. **Load** - Chargement batch ClickHouse
4. **Validate** - V√©rification qualit√© (count match)
5. **Notify** - Notification de fin

**Visualisation:**
```
extract_from_postgres >> transform_transactions >> load_to_clickhouse 
                      >> validate_data_quality >> send_completion_notification
```

---

### 2. **data_quality_checks**
**Fr√©quence:** Quotidienne (6h du matin)

Validation automatis√©e de la qualit√© des donn√©es.

**V√©rifications:**
- ‚úÖ Valeurs NULL interdites
- ‚úÖ Types de donn√©es (amount > 0, fraud_score 0-100)
- ‚úÖ Int√©grit√© r√©f√©rentielle (FK valides)
- ‚ö†Ô∏è  R√®gles m√©tier (fraud_score vs is_fraud coh√©rent)

---

### 3. **daily_aggregations**
**Fr√©quence:** Quotidienne (3h du matin, apr√®s ETL)

Pr√©-calcul des m√©triques analytics pour dashboards Grafana.

**Tables cr√©√©es:**
- `daily_stats` - Statistiques globales quotidiennes
- `merchant_daily_stats` - M√©triques par marchand
- `user_daily_stats` - M√©triques par utilisateur
- `hourly_patterns` - Patterns horaires (d√©tection anomalies)

**Optimisation:** OPTIMIZE TABLE automatique apr√®s agr√©gations

---

## üöÄ D√©marrage Rapide

### Lancer Airflow avec la plateforme

```bash
# Lancer tous les services (inclut Airflow)
docker-compose up -d

# V√©rifier qu'Airflow est pr√™t
docker-compose logs -f airflow-webserver

# Ouvrir l'interface
open http://localhost:8080
```

### Activer les DAGs

Par d√©faut, les DAGs sont **d√©sactiv√©s**. Pour les activer :

1. Ouvrir http://localhost:8080
2. Se connecter (admin / stripe_password)
3. Cliquer sur le toggle √† gauche de chaque DAG
4. Les DAGs s'ex√©cuteront selon leur schedule

### Ex√©cution manuelle

Pour tester imm√©diatement un DAG :

1. Cliquer sur le nom du DAG
2. Cliquer sur le bouton "‚ñ∂Ô∏è Trigger DAG" en haut √† droite
3. Observer l'ex√©cution en temps r√©el dans "Graph View"

---

## üìà Monitoring

### Logs des t√¢ches

1. Cliquer sur un DAG
2. Cliquer sur un run
3. Cliquer sur une t√¢che
4. Onglet "Logs" pour voir les d√©tails

### M√©triques de performance

- **Duration:** Temps d'ex√©cution de chaque t√¢che
- **Success Rate:** Taux de r√©ussite historique
- **Next Run:** Prochaine ex√©cution programm√©e

---

## üõ†Ô∏è D√©veloppement de DAGs

### Structure d'un DAG

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import timedelta

default_args = {
    'owner': 'david_rambeau',
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'mon_dag',
    default_args=default_args,
    schedule_interval='0 2 * * *',  # Cron expression
    catchup=False,
    tags=['custom'],
) as dag:
    
    task = PythonOperator(
        task_id='ma_tache',
        python_callable=ma_fonction,
    )
```

### Ajouter un nouveau DAG

1. Cr√©er un fichier Python dans `/airflow/dags/`
2. Red√©marrer Airflow : `docker-compose restart airflow-scheduler`
3. Le DAG appara√Æt automatiquement dans l'interface

---

## üîß Configuration

### Variables d'environnement

D√©finies dans `docker-compose.yml` :

```yaml
POSTGRES_HOST: postgres
CLICKHOUSE_HOST: clickhouse
MONGODB_HOST: mongodb
...
```

### Connexions

Airflow se connecte directement aux bases via les variables d'environnement.  
Pas besoin de configurer les "Connections" dans l'UI.

---

## üìä Int√©gration avec Grafana

Les tables agr√©g√©es par Airflow alimentent les dashboards Grafana :

- `daily_stats` ‚Üí Dashboard "Transaction Volume"
- `merchant_daily_stats` ‚Üí Dashboard "Top Merchants"
- `hourly_patterns` ‚Üí Dashboard "Fraud Patterns by Hour"

---

## üéì Certification AIA - Bloc 3

Ces DAGs d√©montrent les comp√©tences suivantes :

‚úÖ **Orchestration ETL** - Apache Airflow  
‚úÖ **Pipelines automatis√©s** - Scheduling quotidien  
‚úÖ **Data Quality** - Validation automatis√©e  
‚úÖ **Agr√©gations batch** - Pr√©-calcul m√©triques  
‚úÖ **Monitoring** - Logs, alertes, retry  
‚úÖ **Scalabilit√©** - Traitement par batch  

---

## üìû Support

En cas de probl√®me :

```bash
# V√©rifier les logs Airflow
docker-compose logs airflow-scheduler
docker-compose logs airflow-webserver

# Red√©marrer Airflow
docker-compose restart airflow-scheduler airflow-webserver

# R√©initialiser la BDD Airflow (attention : perte historique)
docker-compose down
docker volume rm dataarch_airflow_postgres_data
docker-compose up -d
```

---

**Airflow transforme votre architecture en un syst√®me de donn√©es industrialis√© et automatis√© ! üöÄ**
